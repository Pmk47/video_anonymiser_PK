<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1" />
<title>Real-time Eye Anonymiser</title>
<style>
  body { margin:0; font-family:system-ui, sans-serif; background:#0b0f14; color:#eaf2ff; }
  header { padding:12px 16px; font-weight:600; }
  main { display:flex; flex-direction:column; gap:12px; padding:0 12px 16px; }
  .video-wrap { position:relative; width:100%; max-width:720px; margin:0 auto; }
  video, canvas { width:100%; border-radius:12px; background:#000; }
  #overlay { position:absolute; inset:0; pointer-events:none; }
  .controls { display:flex; gap:10px; align-items:center; justify-content:center; flex-wrap:wrap; }
  button { padding:10px 14px; border-radius:10px; border:1px solid #2a3a4d; background:#142132; color:#eaf2ff; font-weight:600; }
  button:disabled { opacity:.5; }
  label { color:#9bb0c9; font-size:14px; margin:0 4px; }
  select, input[type=number] { padding:6px; border-radius:6px; border:1px solid #2a3a4d; background:#0f1722; color:#eaf2ff; }
  .row { display:flex; gap:8px; flex-wrap:wrap; justify-content:center; align-items:center; }
  .hint { color:#9bb0c9; font-size:13px; text-align:center; flex-basis:100%; }
  .timer { font-weight:700; color:#6ec1ff; }
</style>
</head>
<body>
<header>üëÅÔ∏è‚Äçüó®Ô∏è Eye Anonymiser ‚Äî Black Box / Blur</header>
<main>
  <div class="video-wrap">
    <video id="raw" playsinline muted style="display:none"></video>
    <canvas id="out"></canvas>
    <canvas id="overlay" style="display:none;"></canvas>
  </div>

  <div class="controls">
    <div class="row">
      <label>Mode:</label>
      <select id="mode">
        <option value="black" selected>Black Box</option>
        <option value="blur">Blur</option>
      </select>
      <label>Resolution:</label>
      <select id="resolution">
        <option value="1920x1080">1080p</option>
        <option value="1280x720" selected>720p</option>
      </select>
      <label>FPS:</label>
      <select id="fps">
        <option value="30" selected>30</option>
        <option value="24">24</option>
      </select>
      <label>Duration(s):</label>
      <input id="duration" type="number" value="120" min="10" max="600"/>
    </div>
    <div class="row">
      <button id="startBtn">Start</button>
      <button id="stopBtn" disabled>Stop</button>
      <label><input id="showOverlay" type="checkbox"> Debug overlay</label>
    </div>
    <div class="row">
      <span class="hint">Anonymisation is done in-browser, nothing uploaded.</span>
      <span class="timer" id="timer">00:00</span>
    </div>
  </div>
</main>

<!-- TFJS + FaceMesh -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.20.0/dist/tf-core.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.20.0/dist/tf-backend-webgl.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.20.0/dist/tf-converter.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@2.0.1/dist/face-landmarks-detection.min.js"></script>

<script>
(async () => {
  const els = {
    raw: raw, out: out, overlay: overlay,
    start: startBtn, stop: stopBtn, mode: mode,
    res: resolution, fps: fps, dur: duration,
    show: showOverlay, timer: timer
  };

  await tf.setBackend('webgl');
  const model = await faceLandmarksDetection.load(
    faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,
    { maxFaces: 1 }
  );

  const LEFT = [33,7,163,144,145,153,154,155,133,173,157,158,159,160,161,246];
  const RIGHT= [263,249,390,373,374,380,381,382,362,398,384,385,386,387,388,466];

  let stream, rec, chunks=[], raf, startTime, stopId;
  const off = document.createElement('canvas'); const offCtx=off.getContext('2d');

  function eyeBox(pts, padX=10, padY=8) {
    let xs=pts.map(p=>p.x), ys=pts.map(p=>p.y);
    return [Math.min(...xs)-padX, Math.min(...ys)-padY,
            Math.max(...xs)-Math.min(...xs)+2*padX,
            Math.max(...ys)-Math.min(...ys)+2*padY];
  }

  function drawMask(ctx, mode, pts) {
    if(!pts.length) return;
    const [x,y,w,h]=eyeBox(pts);
    if(mode==='black'){
      ctx.fillStyle='#000'; ctx.fillRect(x,y,w,h);
    } else if(mode==='blur'){
      off.width=w; off.height=h;
      offCtx.clearRect(0,0,w,h);
      offCtx.drawImage(ctx.canvas, x,y,w,h, 0,0,w,h);
      ctx.save(); ctx.filter='blur(12px)';
      ctx.drawImage(off, x,y,w,h,h);
      ctx.restore();
    }
  }

  async function startCam() {
    const [w,h]=els.res.value.split('x').map(Number);
    stream = await navigator.mediaDevices.getUserMedia({
      video:{width:{ideal:w},height:{ideal:h},facingMode:{exact:"environment"}},
      audio:false
    }).catch(()=>navigator.mediaDevices.getUserMedia({video:{width:w,height:h},audio:false}));
    els.raw.srcObject=stream; await els.raw.play();
    els.out.width=els.raw.videoWidth; els.out.height=els.raw.videoHeight;
    els.overlay.width=els.out.width; els.overlay.height=els.out.height;
    return {w:els.out.width,h:els.out.height,fps:+els.fps.value};
  }

  function save() {
    const blob=new Blob(chunks,{type:rec.mimeType}); const url=URL.createObjectURL(blob);
    const a=document.createElement('a'); a.href=url; a.download=`anonymised_${Date.now()}.webm`;
    a.click(); setTimeout(()=>URL.revokeObjectURL(url),200);
  }

  function stopAll(){ cancelAnimationFrame(raf); clearTimeout(stopId);
    if(rec && rec.state!=='inactive') rec.stop(); els.start.disabled=false; els.stop.disabled=true; }

  async function loop(ctx,w,h) {
    raf=requestAnimationFrame(()=>loop(ctx,w,h));
    ctx.drawImage(els.raw,0,0,w,h);
    const faces=await model.estimateFaces({input:els.raw});
    if(faces.length){
      const k=faces[0].keypoints; const m=els.mode.value;
      drawMask(ctx,m,LEFT.map(i=>k[i])); drawMask(ctx,m,RIGHT.map(i=>k[i]));
    }
    const s=Math.floor((performance.now()-startTime)/1000);
    els.timer.textContent=`${String(Math.floor(s/60)).padStart(2,'0')}:${String(s%60).padStart(2,'0')}`;
  }

  els.start.onclick=async()=>{
    els.start.disabled=true; els.stop.disabled=false;
    const {w,h,fps}=await startCam(); const ctx=els.out.getContext('2d');
    rec=new MediaRecorder(els.out.captureStream(fps),{mimeType:'video/webm'});
    chunks=[]; rec.ondataavailable=e=>e.data.size&&chunks.push(e.data); rec.onstop=save;
    rec.start(1000); startTime=performance.now();
    loop(ctx,w,h); stopId=setTimeout(stopAll,els.dur.value*1000);
  };
  els.stop.onclick=stopAll;
})();
</script>
</body>
</html>
